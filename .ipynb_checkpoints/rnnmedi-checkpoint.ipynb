{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6cc6c2-70d0-4d8d-b5d4-3e1337b52764",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b97480-2a35-4f4d-98ac-afb779d8646e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Embedding, Dropout\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697a744-5fac-4595-a1a7-a1dc081d3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('Training.csv')\n",
    "X = data.drop('prognosis', axis=1).values  # Symptoms\n",
    "y = data['prognosis'].values  # Disease labels\n",
    "\n",
    "# Encode disease labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Tokenizing symptoms\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X.astype(str))\n",
    "X_sequences = tokenizer.texts_to_sequences(X.astype(str))\n",
    "X_padded = pad_sequences(X_sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8db6b9-dd33-468f-9350-7c526bd6792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.3, random_state=20)\n",
    "\n",
    "# Define RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=X_padded.shape[1]),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save model\n",
    "model.save('rnn_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ad3618-a728-4e12-bcdf-126d559efa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load supporting datasets\n",
    "sym_des = pd.read_csv(\"symtoms_df.csv\")\n",
    "precautions = pd.read_csv(\"precautions_df.csv\")\n",
    "workout = pd.read_csv(\"workout_df.csv\")\n",
    "description = pd.read_csv(\"description.csv\")\n",
    "medications = pd.read_csv('medications.csv')\n",
    "diets = pd.read_csv(\"diets.csv\")\n",
    "\n",
    "# Load trained model\n",
    "model = load_model('rnn_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af3569-cb3a-4aa5-9a54-7326402c0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_value(patient_symptoms):\n",
    "    input_vector = np.zeros(len(tokenizer.word_index) + 1)\n",
    "    for symptom in patient_symptoms:\n",
    "        if symptom in tokenizer.word_index:\n",
    "            input_vector[tokenizer.word_index[symptom]] = 1\n",
    "    input_vector = pad_sequences([input_vector], maxlen=X_padded.shape[1], padding='post')\n",
    "    prediction = np.argmax(model.predict(input_vector))\n",
    "    return le.inverse_transform([prediction])[0]\n",
    "\n",
    "def helper(dis):\n",
    "    desc = description[description['Disease'] == dis]['Description'].values[0]\n",
    "    pre = precautions[precautions['Disease'] == dis][['Precaution_1', 'Precaution_2', 'Precaution_3', 'Precaution_4']].values[0]\n",
    "    med = medications[medications['Disease'] == dis]['Medication'].values\n",
    "    die = diets[diets['Disease'] == dis]['Diet'].values\n",
    "    wrkout = workout[workout['disease'] == dis]['workout'].values\n",
    "    return desc, pre, med, die, wrkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747724c-43f9-4abd-b183-521b4f8317e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input\n",
    "symptoms = input(\"Enter your symptoms (comma-separated): \")\n",
    "user_symptoms = [s.strip() for s in symptoms.split(',')]\n",
    "predicted_disease = get_predicted_value(user_symptoms)\n",
    "\n",
    "desc, pre, med, die, wrkout = helper(predicted_disease)\n",
    "\n",
    "print(\"================= Predicted Disease ============\")\n",
    "print(predicted_disease)\n",
    "print(\"================= Description ==================\")\n",
    "print(desc)\n",
    "print(\"================= Precautions ==================\")\n",
    "for i, p in enumerate(pre, start=1):\n",
    "    print(f\"{i}: {p}\")\n",
    "print(\"================= Medications ==================\")\n",
    "for i, m in enumerate(med, start=1):\n",
    "    print(f\"{i}: {m}\")\n",
    "print(\"================= Workout ==================\")\n",
    "for i, w in enumerate(wrkout, start=1):\n",
    "    print(f\"{i}: {w}\")\n",
    "print(\"================= Diets ==================\")\n",
    "for i, d in enumerate(die, start=1):\n",
    "    print(f\"{i}: {d}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
